{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>18</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>19256</td>\n",
       "      <td>320</td>\n",
       "      <td>619</td>\n",
       "      <td>23366</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>1732670</td>\n",
       "      <td>17</td>\n",
       "      <td>14521</td>\n",
       "      <td>120347</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>298</td>\n",
       "      <td>198</td>\n",
       "      <td>146</td>\n",
       "      <td>219410</td>\n",
       "      <td>378</td>\n",
       "      <td>3479</td>\n",
       "      <td>9814</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>86</td>\n",
       "      <td>121</td>\n",
       "      <td>12235</td>\n",
       "      <td>93651</td>\n",
       "      <td>4311</td>\n",
       "      <td>358</td>\n",
       "      <td>32377</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112</td>\n",
       "      <td>69</td>\n",
       "      <td>116</td>\n",
       "      <td>81</td>\n",
       "      <td>50163</td>\n",
       "      <td>920</td>\n",
       "      <td>1730</td>\n",
       "      <td>153206</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text  favorite_count  retweet_count  favourites_count  followers_count  \\\n",
       "0    90              18            115                 2            19256   \n",
       "1    36              29            164                 1          1732670   \n",
       "2    43             298            198               146           219410   \n",
       "3    78              86            121             12235            93651   \n",
       "4   112              69            116                81            50163   \n",
       "\n",
       "   friends_count  listed_count  statuses_count  verified  class  \n",
       "0            320           619           23366      True      1  \n",
       "1             17         14521          120347      True      1  \n",
       "2            378          3479            9814      True      1  \n",
       "3           4311           358           32377     False      1  \n",
       "4            920          1730          153206     False      1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import preprocessing,cross_validation, neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from __future__ import division\n",
    "import string\n",
    "import math\n",
    "tokenize = lambda doc: doc.lower().split(\" \")\n",
    "import re\n",
    "from bs4.element import Comment\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.svm import LinearSVC\n",
    " \n",
    "\n",
    "tokenize = lambda doc: doc.lower().split(\" \")\n",
    "\n",
    "\n",
    "\n",
    "HOUSING_PATH = \"C:/Users/vaibhav singh/Desktop/proj/benchmark_pheme\"\n",
    "def load_sample_data(housing_path=HOUSING_PATH): \n",
    "    os.chdir(housing_path) \n",
    "    return pd.read_csv(\"sydneysiege.csv\")\n",
    "\n",
    "\n",
    "# In[264]:\n",
    "\n",
    "\n",
    "sample = load_sample_data()\n",
    "\n",
    "\n",
    "\n",
    "sample.drop('contributors',axis=1,inplace=True)\n",
    "sample.drop('truncated',axis=1,inplace=True)\n",
    "#sample.drop('text',axis=1,inplace=True)\n",
    "sample.drop('description',axis=1,inplace=True)\n",
    "sample.drop('profile_use_background_image',axis=1,inplace=True)\n",
    "sample.drop('default_profile',axis=1,inplace=True)\n",
    "sample.drop('following',axis=1,inplace=True)\n",
    "sample.drop('geo_enabled',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "sample.drop('created_at',axis=1,inplace=True)\n",
    "sample.drop('in_reply_to_status_id_str',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('in_reply_to_status_id',axis=1,inplace=True)\n",
    "sample.drop('retweeted',axis=1,inplace=True)\n",
    "sample.drop('coordinates',axis=1,inplace=True)\n",
    "sample.drop('source',axis=1,inplace=True)\n",
    "sample.drop('in_reply_to_screen_name',axis=1,inplace=True)\n",
    "sample.drop('id_str',axis=1,inplace=True)\n",
    "sample.drop('favorited',axis=1,inplace=True)\n",
    "sample.drop('geo',axis=1,inplace=True)\n",
    "sample.drop('in_reply_to_user_id_str',axis=1,inplace=True)\n",
    "sample.drop('lang',axis=1,inplace=True)\n",
    "sample.drop('place',axis=1,inplace=True)\n",
    "sample.drop('contributors_enabled',axis=1,inplace=True)\n",
    "sample.drop('user_created_at',axis=1,inplace=True)\n",
    "sample.drop('default_profile_image',axis=1,inplace=True)\n",
    "\n",
    "#sample.drop('description',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('follow_request_sent',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "sample.drop('location',axis=1,inplace=True)\n",
    "sample.drop('entities_hashtags',axis=1,inplace=True)\n",
    "sample.drop('id_protectedstr',axis=1,inplace=True)\n",
    "sample.drop('screen_name',axis=1,inplace=True)\n",
    "sample.drop('name',axis=1,inplace=True)\n",
    "sample.drop('notifications',axis=1,inplace=True)\n",
    "sample.drop('time_zone',axis=1,inplace=True)\n",
    "sample.drop('utc_offset',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('id',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('in_reply_to_user_id',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('profile_text_color',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('entities_symbols',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('entities_user_mentions',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('entities_urls',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('user_idstr',axis=1,inplace=True)\n",
    "sample.drop('profile_link_color',axis=1,inplace=True)\n",
    "sample.drop('profile_image_url',axis=1,inplace=True)\n",
    "sample.drop('profile_background_tile',axis=1,inplace=True)\n",
    "sample.drop('profile_background_color',axis=1,inplace=True)\n",
    "sample.drop('profile_background_image_url',axis=1,inplace=True)\n",
    "sample.drop('profile_background_image_url_https',axis=1,inplace=True)\n",
    "sample.drop('profile_image_url_https',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('user_id',axis=1,inplace=True)\n",
    "sample.drop('profile_sidebar_fill_color',axis=1,inplace=True)\n",
    "sample.drop('profile_sidebar_border_color',axis=1,inplace=True)\n",
    "#sample.drop('possibly_sensitive',axis=1,inplace=True)\n",
    "#sample.drop('is_translation_enabled',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "def term_frequency(term, tokenized_document):\n",
    "    return tokenized_document.count(term)\n",
    "\n",
    "def sublinear_term_frequency(term, tokenized_document):\n",
    "    count = tokenized_document.count(term)\n",
    "    if count == 0:\n",
    "        return 0\n",
    "    return 1 + math.log(count)\n",
    "\n",
    "def augmented_term_frequency(term, tokenized_document):\n",
    "    max_count = max([term_frequency(t, tokenized_document) for t in tokenized_document])\n",
    "    return (0.5 + ((0.5 * term_frequency(term, tokenized_document))/max_count))\n",
    "\n",
    "def inverse_document_frequencies(tokenized_documents):\n",
    "    idf_values = {}\n",
    "    all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
    "    for tkn in all_tokens_set:\n",
    "        contains_token = map(lambda doc: tkn in doc, tokenized_documents)\n",
    "        idf_values[tkn] = 1 + math.log(len(tokenized_documents)/(sum(contains_token)))\n",
    "    return idf_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "words=list(sample['text'])\n",
    "\n",
    "#words2=list(sample['description'])\n",
    "\n",
    "\n",
    "def tfidf(documents):\n",
    "    tokenized_documents = [tokenize(d) for d in documents]\n",
    "    idf = inverse_document_frequencies(tokenized_documents)\n",
    "    tfidf_documents = []\n",
    "    for document in tokenized_documents:\n",
    "        doc_tfidf = []\n",
    "        for term in idf.keys():\n",
    "            tf = sublinear_term_frequency(term, document)\n",
    "            doc_tfidf.append(tf * idf[term])\n",
    "        tfidf_documents.append(doc_tfidf)\n",
    "    return tfidf_documents\n",
    "\n",
    "#rint(words)\n",
    "#words = (list([mails['label'] == 0]['message']))\n",
    "\n",
    "\n",
    "tfi = tfidf(words)\n",
    "#tf2=  tfidf(words2)\n",
    "\n",
    "\n",
    "def sumx(vector1):\n",
    "    s=sum(p for p in (vector1))\n",
    "    return s\n",
    "j=0\n",
    "\n",
    "\n",
    "for i in tfi:\n",
    "    t=sumx(i)\n",
    "    \n",
    "    sample.iat[j,0]=t\n",
    "    j=j+1\n",
    "j=0\n",
    "\n",
    "\"\"\"for i in tf2:\n",
    "    t=sumx(i)\n",
    "    \n",
    "    sample.iat[j,4]=t\n",
    "    j=j+1\n",
    "\"\"\"\n",
    "   \n",
    "\n",
    "sample['text']=sample.text.astype(int)\n",
    "#sample['description']=sample.description.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[274]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "\n",
      "accuracy\n",
      "0.690909090909\n",
      "f1_score \n",
      "0.689986737401\n",
      "precision \n",
      "0.689837802052\n",
      "recall \n",
      "0.690594882021\n",
      "\n",
      "\n",
      "MLP\n",
      "\n",
      "accuracy\n",
      "0.690909090909\n",
      "accuracy\n",
      "0.536363636364\n",
      "f1_score \n",
      "0.349112426036\n",
      "precision\n",
      "0.268181818182\n",
      "recall\n",
      "0.5\n",
      "random forest\n",
      "\n",
      "accuracy\n",
      "0.727272727273\n",
      "f1_score\n",
      "0.726708074534\n",
      "precision\n",
      "0.726686507937\n",
      "recall\n",
      "0.727816550349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd classifier\n",
      "\n",
      "accuracy\n",
      "0.604545454545\n",
      "f1_score\n",
      "0.580180298743\n",
      "precision\n",
      "0.680093089868\n",
      "recall\n",
      "0.625373878365\n",
      "naive baiyes\n",
      "\n",
      "accuracy\n",
      "0.531818181818\n",
      "0.386755432871\n",
      "0.495215311005\n",
      "0.499086075108\n",
      "multinomial nb \n",
      "\n",
      "accuracy\n",
      "0.545454545455\n",
      "\n",
      "\n",
      "0.497441520468\n",
      "0.536470588235\n",
      "0.525756065138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x=np.array(sample.drop(['class'],1))\n",
    "y=np.array(sample['class'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test= cross_validation.train_test_split(x,y,test_size=0.18)\n",
    "\n",
    "clf=neighbors.KNeighborsClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"KNN\\n\")\n",
    "print(\"accuracy\")\n",
    "print(clf.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "print(\"f1_score \")\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"precision \")\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"recall \")\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nclf=MLPClassifier(solver=\"lbfgs\",alpha=1e-5,hidden_layer_sizes=(100,80,30,10,1))\n",
    "nclf.fit(x_train,y_train)\n",
    "y_pred0 = nclf.predict(x_test)\n",
    "\n",
    "print(\"MLP\\n\")\n",
    "print(\"accuracy\")\n",
    "print(clf.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "print(\"accuracy\")\n",
    "print(nclf.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "print(\"f1_score \")\n",
    "print(f1_score(y_test, y_pred0, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"precision\")\n",
    "print(precision_score(y_test, y_pred0, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"recall\")\n",
    "print(recall_score(y_test, y_pred0, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=41, oob_score=True, random_state=156)\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred2 = rf.predict(x_test)\n",
    "print(\"random forest\\n\")\n",
    "print(\"accuracy\")\n",
    "print(rf.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "print(\"f1_score\")\n",
    "print(f1_score(y_test, y_pred2, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"precision\")\n",
    "print(precision_score(y_test, y_pred2, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"recall\")\n",
    "print(recall_score(y_test, y_pred2, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=60, max_iter=800) # if you want reproducible results set the random_state value.\n",
    "sgd_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred3 = sgd_clf.predict(x_test)\n",
    "print(\"sgd classifier\\n\")\n",
    "print(\"accuracy\")\n",
    "print(sgd_clf.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "print(\"f1_score\")\n",
    "print(f1_score(y_test, y_pred3, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"precision\")\n",
    "print(precision_score(y_test, y_pred3, average=\"macro\"))\n",
    "\n",
    "#print(\"\\n\")\n",
    "print(\"recall\")\n",
    "print(recall_score(y_test, y_pred3, average=\"macro\")) \n",
    "#print(\"\\n\")\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bnb = BernoulliNB(binarize=0.70)\n",
    "bnb.fit(x_train, y_train)\n",
    "y_pred4 = bnb.predict(x_test)\n",
    "\n",
    "print(\"naive baiyes\\n\")\n",
    "print(\"accuracy\")\n",
    "print(bnb.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "\n",
    "print(f1_score(y_test, y_pred4, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred4, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred4, average=\"macro\")) \n",
    "#print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# In[212]:\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train, y_train)\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "mnb.score(x_test,y_test)\n",
    "\n",
    "print(\"multinomial nb \\n\")\n",
    "print(\"accuracy\")\n",
    "print(mnb.score(x_test,y_test))\n",
    "print(\"\\n\")\n",
    "y_pred5 = mnb.predict(x_test)\n",
    "print(f1_score(y_test, y_pred5, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred5, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred5, average=\"macro\"))  \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm=SVC(kernel=\"linear\",C=0.025,random_state=101)\n",
    "svm.fit(x_train,y_train)\n",
    "y_pred6=svm.predict(x_test)\n",
    "print(\"svm \\n\")\n",
    "print(\"accuracy\")\n",
    "print(svm.score(x_test,y_test))\n",
    "print(\"\\n\")\n",
    "print(svm.score(x_test,y_test))\n",
    "print(f1_score(y_test, y_pred6, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred6, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred6, average=\"macro\"))  \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred7=lr.predict(x_test)\n",
    "print(\"logistic regression \\n\")\n",
    "print(\"accuracy\")\n",
    "print(mnb.score(x_test,y_test))\n",
    "print(\"\\n\")\n",
    "print(lr.score(x_test,y_test))\n",
    "print(f1_score(y_test, y_pred7, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred7, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred7, average=\"macro\"))  \n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier(max_depth=10,random_state=101, max_features=None, min_samples_leaf=15)\n",
    "dtree.fit(x_train,y_train)\n",
    "y_pred=dtree.predict(x_test)\n",
    "print(\"decision tree \\n\")\n",
    "print(\"accuracy\")\n",
    "print(dtree.score(x_test,y_test))\n",
    "print(\"\\n\")\n",
    "print(dtree.score(x_test,y_test))\n",
    "print(f1_score(y_test, y_pred7, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred7, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred7, average=\"macro\"))  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
